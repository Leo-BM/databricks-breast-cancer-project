#  Breast Cancer Detection: SVM Analysis on Databricks

> **Estudo de Caso:** Comparativo entre Engenharia de Features (Spark ML) e Kernel Methods (Scikit-Learn) para classifica√ß√£o de dados m√©dicos.

## Sobre o Projeto

Este projeto explora a implementa√ß√£o do algoritmo **Support Vector Machines (SVM)** em um ambiente de nuvem (**Databricks**). 

Embora o dataset utilizado (*Breast Cancer Wisconsin*) seja pequeno o suficiente para processamento local, optou-se intencionalmente pelo uso do **Apache Spark** para simular um pipeline de Engenharia de Machine Learning escal√°vel. O objetivo foi validar como t√©cnicas de *Large Scale Machine Learning* se comparam a m√©todos tradicionais *in-memory* em cen√°rios de alta complexidade te√≥rica (n√£o-linearidade).

##  Objetivos de Neg√≥cio e T√©cnica

1.  **Infraestrutura:** Configurar um fluxo completo (End-to-End) no Databricks (Ingest√£o, Tratamento, Modelagem).
2.  **Teoria SVM:** Implementar os conceitos de *Large Margin Classification* e *Kernel Trick*.
3.  **M√©trica Cr√≠tica:** Em diagn√≥stico de c√¢ncer, a **Acur√°cia** √© secund√°ria. O foco total deste estudo foi maximizar o **Recall (Sensibilidade)** para minimizar Falsos Negativos (pacientes doentes diagnosticados como saud√°veis).

##  Tech Stack

* **Plataforma:** Databricks Community Edition
* **Processamento Distribu√≠do:** PySpark (MLlib)
* **Modelagem Comparativa:** Scikit-Learn
* **Linguagem:** Python 3.x
* **Conceitos:** SVM, Pipelines, Polynomial Expansion, RBF Kernel.

##  A Batalha dos Modelos

Implementamos tr√™s abordagens distintas para resolver o problema de classifica√ß√£o:

### 1. Spark Linear SVC
* **Abordagem:** Modelo linear padr√£o escal√°vel.
* **Resultado:** Sofreu *underfitting* devido √† natureza n√£o-linear das fronteiras de decis√£o do c√¢ncer.

### 2. Spark Polynomial SVC (Feature Engineering)
* **Abordagem:** Como o Spark n√£o possui Kernel RBF nativo (devido ao custo computacional em Big Data), simulamos a n√£o-linearidade expandindo as features matematicamente (`PolynomialExpansion` de grau 2).
* **Resultado:** Aumento significativo na acur√°cia, provando que a engenharia de dados pode compensar limita√ß√µes algor√≠tmicas.

### 3. Scikit-Learn SVC (RBF Kernel)
* **Abordagem:** Uso do "Kernel Trick" (Radial Basis Function) processando os dados em mem√≥ria (Driver Node).
* **Resultado:** Capaz de desenhar fronteiras de decis√£o complexas e org√¢nicas ("ilhas" de decis√£o).

## üìä Resultados Finais

| Modelo | Acur√°cia Global | Recall (Maligno) | An√°lise |
| :--- | :--- | :--- | :--- |
| **Spark Linear** | ~95.1% | 87.93% | Incapaz de capturar complexidade geom√©trica. |
| **Spark Polinomial** | ~97.9% | 94.83% | √ìtima generaliza√ß√£o, mas computacionalmente custoso (muitas features). |
| **Scikit-Learn RBF** | **~98.2%** | 96.83% | O melhor equil√≠brio. O Kernel RBF conseguiu isolar os casos dif√≠ceis, maximizando a detec√ß√£o de doentes. |

> **Conclus√£o:** Para este volume de dados, a abordagem matem√°tica refinada do Scikit-Learn (RBF) superou a for√ßa bruta do Spark. No entanto, o pipeline do Spark est√° pronto para ser plugado em bases de Terabytes, onde o Scikit-Learn falharia.

## Aprendizados Chave

* **Databricks & Spark:** O uso de `VectorAssembler` e `Pipelines` garante que o pr√©-processamento (como `StandardScaler`, crucial para SVM) seja reproduz√≠vel em produ√ß√£o.
* **O Dilema do Kernel:** Em Big Data, muitas vezes trocamos algoritmos complexos (Kernels) por mais dados ou mais features (Expans√£o Polinomial).
* **Medicina vs. Matem√°tica:** O ajuste de *Threshold* (limiar de decis√£o) foi essencial para priorizar a vida (Recall) em detrimento da precis√£o pura.

---
Desenvolvido por **Leonardo Bento Maria**
